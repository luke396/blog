---
title: "2023HW02: 深度学习调参实战记录 - MLP与RNN调优经验总结"
date: "2025-08-16T13:49:33+08:00"
draft: false
description: "基于李宏毅课程HW02的深度学习模型调参实战记录，包含MLP和RNN模型的完整调优过程、理论思考和最佳实践总结"
tags:
    - deep-learning
    - hyperparameter-tuning
    - model-optimization
    - overfitting
    - regularization
    - neural-networks
    - rnn
    - lstm
keywords:
    - deep-learning-tuning
    - mlp-optimization
    - rnn-hyperparameters
    - overfitting-solutions
    - batch-normalization
    - dropout-regularization
series: "hylee"
---

<!--more-->

## AI总结

### 调参优先级的重要发现

根据实际实验结果，学习率调优的效果超出预期：

- 最终性能提升主要来自学习率调整，而非模型架构改动
- Learning Rate Finder + One Cycle 调度器相比手动调整更稳定
- 先增加总参数量，再调整具体的宽度深度配比更有效

### 实验验证的调参顺序

1. **学习率优化**：使用 LR Finder 找区间，One Cycle 调度器控制
2. **模型容量调整**：逐步增加直到出现过拟合迹象
3. **正则化技术**：根据过拟合程度应用 dropout、weight decay
4. **细节迭代**：在稳定基础上进行小幅调整

### MLP实验的具体发现

- Batch Normalization 加入后效果立即改善
- Dropout 从 0.5 → 0.3 → 0.4 的调整过程显示需要与学习率配合
- 翻倍 batch size 在特定配置下有正面效果
- Batch Normalization + Dropout 组合需要调整学习率来保持效果

### RNN实验的关键收获

- **特征工程发现**：n-frame 从 25 → 13 → 1，最终 n-frame=1 效果最好
- **架构选择**：Layer Normalization 对 RNN 效果明显好于 Batch Normalization
- **容量搜索结果**：层数增加(2→3→4)持续有效，宽度 256→384 提升明显，384→512 收益减少
- **资源效率**：hd512,l4 比 hd384,l4 性能提升约1pp，但训练成本增加约1.8倍

### 理论理解的澄清

- Cross Entropy 与准确率可能出现相反趋势，这是正常现象
- 验证损失上升但验证准确率仍能上升，因为二者关注的分布信息不同
- 激进的学习率调度曲线（小区间余弦）比长训练周期更有效

### 实际应用建议

- 网格搜索比随机尝试更系统有效
- 对于时序数据，LSTM 本身的时序建模能力使得过多特征拼接变得多余
- AdamW 与 Adam 在此实验中差异不大
- 过拟合典型表现：训练准确率 97-98% vs 验证准确率 80-81%

### 方法论总结

最重要的收获是调参顺序的重要性：优先调整学习率和调度策略，在稳定的训练基础上再优化模型容量和正则化技术。这与常见的"先调模型再调学习率"的做法相反，但实验证明更有效。

---

## 调参理论基础

### 基本原则与经验法则

- 先尝试最简单的模型/特征集
- 逐步增加模型容量，同时监控验证误差
- 如果验证误差开始上升：(a) 加入正则化，(b) 收集更多数据，或 (c) 减少特征/参数

### 模型容量与数据平衡

**容量优化策略**：

- 相比于调整宽度和深度的排列组合，先直接把参数量（宽度 × 深度）堆上去最重要
- 先调整模型容量，然后到达平台期/过拟合，再尝试增加数据
- 然后才是调整宽度和深度的细节

**数据增强的理解**：

- 增加数据指的是增加样本数量，这是在增加输入空间的覆盖范围 (coverage of input space)
- 这通常有助于减少过拟合，可以帮助增加模型容量 (add capacity)
- 而不是增加特征，这是在使得输入更加高维，却没有添加任何约束

### 过拟合现象与诊断

**过拟合的典型表现**：

- 模型越强（参数量越大），更容易得到小的训练损失，但同时也更容易过拟合
- 虽然训练损失在持续下降，但验证损失很快呈现反抛物线
- 参数量与数据量二者比例合适很重要

**容量调优的细节**：

- 在参数总量一定下，宽度 × 深度的微调是有意义的，可以明显观察到验证损失的下降
- 大的隐藏层尺寸，可以接受更大的输入层尺寸
- weight_decay 用于帮助降低过拟合和降低模型复杂度，添加惩罚项以惩罚大权重

### Loss与Accuracy的关系理解

在实验中观察到验证损失持续上升但验证准确率仍能上升的现象，这是正常的，因为：

- Cross Entropy (CE) 与准确率的关注点不同，并不能严格一一对应
- CE 关注的是分布的完整形状，所以输出某个标签概率 0.1 ($-\log(0.1)$) 和 0.001 ($-\log(0.001)$) 对应的损失是大幅上升的，而准确率是不变的
- 随着训练，模型越来越自信，大部分样本的置信度越来越高，也就是越来越倾向于输出靠近 0 和 1，那么**正确样本多 → 准确率稍涨；少数错误样本自信度更高 → 损失上涨**

## MLP实践探索

本部分记录了在MLP模型上的完整调参探索过程，展现了从基础模型建立到正则化技术应用的系统性调优路径。

### 初始模型建立与特征工程

**特征数量调优 (n-frame)**：

- 增加 n-frame 可以理解为增加特征 (feature)，特征过多会导致模型学习过多噪音，较早产生过拟合问题
- 当发现过拟合时，可以逐渐保持模型不变，调低特征数量，以找到模型能够表现良好的特征数量
- 仅更改 n-frame、隐藏层数、隐藏层维度，得到了一个可以通过 medium baseline 但早早过拟合的模型
- 所以下一步，才是利用各种技术来延缓过拟合

**数据集表现观察**：

- 有趣现象：验证集上的准确率和损失都比测试集在数值上表现更好
- 这应该不需要过分担心，应该只是采样随机的问题，二者都正常下降即可

### 正则化技术的系统应用

**Batch Normalization的立竿见影效果**：

- 加入 Batch Normalization 层之后，效果立竿见影地变好

**Dropout调优的复杂过程**：

*初期问题*：

- 在加上 0.5 的 dropout 之后，效果反而下降许多

*解决策略探索*：

- 为了解决 Batch Normalization + Dropout 的效果下降，尝试增大学习率，发现有所提升
- 此时已经达到 strong baseline，但模型还未到精度极限
- 但持续放大学习率所带来的提升很有限

*Dropout强度调整*：

- 把 dropout 调低到 0.3：
  - 衰减正则化程度，提升模型复杂度
  - 观察到初始阶段的精度和训练速度有所提高
  - 看到了熟悉的过拟合现象
  - 尝试降低学习率，效果不明显
- dropout 调回 0.4，仍然过拟合

**Batch Size优化策略**：

- 在 dropout 0.5 + Batch Normalization 下，翻倍 batch size，整体有所提高
- 在学习率 0.001 时，这主要归功于 batch size，模型能够看到更多数据，偏差变小
- 加入 learning rate schedule 进一步优化

## RNN实践进阶

相比MLP，RNN在时序数据处理上的复杂性要求更加系统化的调参策略。本部分记录了从模型基础建立到高级优化技术的完整探索过程。

### 模型基础建立与初始调试

**模型搭建阶段**：

- 终于跑通，时序数据和方法与传统方法有挺多区别，可算是跑通了

**初期问题排查**：

- 遇到 batch size 爆显存的问题，但要先检查是否其他地方有泄露，如果都不是，那就是模型需求太大
- 初始模型配置 (20250721-154530_rnn_nframe25_hl2_hd256_lr0.001_bs128_sched_step10_gamma0.5)：模型基础拟合能力不足，需要先提高，再抑制

### 架构与特征工程优化

**模型容量提升**：

- 提高隐藏层数 (hidden layers) 到 3，隐藏层维度 (hidden dimensions) 到 384，观察到模型能力的上升
- 这相当于增加 LSTM 块的参数量

**时序特征优化的关键发现**：

- 降低 n-frame 从 25 到 13 观察到能力的上升
- 可以解释为特征工程问题：拼接时间跨度太长，无关特征增多，干扰模型
- **最终发现 n-frame=1 效果最好！**

**时序数据理解的深化**：

- 因为 LSTM 从结构设计上已经在进行时序的观察，所以特征拼接就有些多余
- shuffle 只是打断了样本的顺序，但我们仍然保持样本内部的时间顺序，所以 LSTM 可以读取到上下文

**特征设计与模型结构的方法论**：

- 先根据初步模型确定特征数据，然后调整模型参数达到最好
- 接着再微调特征数量等，而不像之前那样大规模进行特征数量的搜索

### 学习率优化的系统方法

**优化顺序的重要原则**：

- 先调学习率，再调模型结构

**Learning Rate Finder + One Cycle 策略**：

- 首先使用 Learning Rate Finder 找到合适的学习率区间
- 然后使用 One Cycle 调度器：
  - 会自动设置余弦曲线、初始值和每个 step 的变化
  - 我们只需要在 optimizer 之后记得调用 schedule.step()，逐步变化即可
  - 设置了 One Cycle 之后，学习率就交由它进行控制，所以模型设置的那个学习率就没有太大意义

**学习率合理性的判断标准**：

- 当观察到训练过程比较平稳，验证准确率平稳上升达到平台期，损失先下降后上升出现过拟合时，可以认为学习率是合理的
- 接下来考虑提升模型泛化能力或者提升模型表达能力再泛化

### 优化器与正则化技术选择

**优化器对比实验**：

- 尝试换到 AdamW（目前更主流的优化器），具体与 Adam 的区别和实现需要补充
- 结果：看起来差别不大

**正则化技术的关键选择**：

- 想到了 Batch Normalization，问了 AI 建议，他们都极力劝阻，但 Layer Normalization 是更合适的
- **Layer Normalization 加上之后效果立竿见影地好**

### 模型容量与正则化的平衡艺术

**三种配置的效果对比**：

1. **无正则化的大模型**：
   - 训练集损失极低，验证集损失很快上升，准确率不涨甚至下降

2. **加正则化的大模型**：
   - 训练损失下降速度变慢，但验证损失更平稳，准确率更高

3. **小模型 + 强正则化**：
   - 训练和验证损失都降不下去，准确率提升缓慢，表现最差

**过拟合问题的实际处理**：

- 咨询后确认目前是典型的过拟合：训练准确率已经到 97-98%，但验证准确率只能到 80-81%
- 训练损失持续下降，但验证损失先下降后上升

**正则化调整策略**：

- 先尝试把 LSTM 内部和全连接层中的 dropout 都从 0.3 提升到 0.5 增加正则化
- 有效果：观察到训练准确率和损失变坏一点，但验证未见提升
- 下一步是增加 AdamW 的 weight decay

### 系统化网格搜索的重要收获

**网格搜索的必要性**：

- 应该早点有意识地进行网格搜索，无论是手动还是自动

**搜索结果分析**：

1. **纵向（固定 hidden_dim）**：
   - 从 2 → 3 → 4 层，验证指标**持续提升**；层数的收益大于宽度

2. **横向（固定 layer）**：
   - hidden_dim 256→384 提升明显（≈+1.5-2 pp）；384→512 **收益减弱**（<1 pp）

3. **资源消耗**：
   - 参数量与 hidden_dim **平方**关系（Bi-LSTM 双向×4 投影矩阵）
   - `hd512, l4` 比 `hd384, l4` 性能 ↑≈1 pp，但参数、训练时长 ↑≈1.8×

4. **过拟合迹象**：
   - 任何配置在 20 epoch 内 **尚未出现验证回升**，说明正则仍充足；因此"再大一点"理论上还有上升空间

**学习率调度的意外收获**：

- 因为换网格搜索，改了 epoch，也就顺便改了学习率的曲线，惊喜地发现，更激进的曲线，即更小区间的余弦曲线，这意味着快速上升和下降，带来了平均更好的结果
- 这也就意味着，epoch 也不是越多越好，尤其是当学习率有自适应算法的时候

### 最佳调参顺序总结

**科学的调参顺序**：

1. **找到稳定的学习率调度**
   - 学习率范围测试 → 选择损失开始剧烈波动之前的最大学习率
   - 决定调度器（One-Cycle、CosineAnnealing 等）

2. **逐步增加容量直到接近过拟合**
   - 增加隐藏层维度/层数，同时观察*训练*损失下降，*验证*损失仍在改善
   - 当验证不再受益或 GPU 预算用尽时停止

3. **应用/强化正则化**
   - 权重衰减、dropout、标签平滑
   - 如果是视觉/音频/NLP 任务，加入数据增强
   - 提前停止，控制训练时间

4. **反复迭代**
   - 改变容量可能需要微调学习率（小幅调整）
   - 改变正则化通常**不需要**大幅度调节学习率

### 关键领悟与收获

- 想不到最后，还真是靠调整学习率，得到了更好的结果，以前一直花大时间鼓捣模型，居然是错误的
- 大力调学习率的同时，大力加了一下 weight decay，也有微弱提升
